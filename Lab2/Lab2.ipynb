{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc0fe02-3eaf-4d84-a6da-5fb41e1960b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57735af2-d88a-493e-9725-0166c341d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f5d3633f-147c-4784-b98d-dacd258e7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Config, Trainer, TrainingArguments, DataCollatorForLanguageModeling, get_linear_schedule_with_warmup\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "dd0778ea-0a30-4f15-bbf7-463a9a70d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7f338656-15ea-4eea-b872-df5be740bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4074e491-d93f-4559-aea5-e5a1b3933dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658eb35f-23b5-41ad-9bbe-c73d6038aef1",
   "metadata": {},
   "source": [
    "1.\tЗагрузка и подготовка корпуса данных: Загрузить текстовый корпус, оценить его объем и структуру.\n",
    "2.\tОчистка данных: Применить разные методы очистки данных, такие как удаление пунктуации, стоп-слов, лемматизация, и оценить их влияние.\n",
    "3.\tТокенизация данных: Преобразовать текстовые данные в числовые представления для последующей обработки трансформером.\n",
    "4.\tСоздание и настройка модели: Инициализировать модель трансформера и настроить гиперпараметры для обучения.\n",
    "5.\tОбучение модели: Провести обучение с использованием разных оптимизаторов и сравнить результаты.\n",
    "6.\tОптимизация модели: Применить различные методы управления скоростью обучения и оценить их влияние на модель.\n",
    "7.\tОценка модели с использованием метрик BLEU, ROUGE и Perplexity: Измерить качество модели с использованием метрик и сравнить результаты.\n",
    "8.\tИнтерактивное тестирование модели: Реализовать интерфейс для взаимодействия с моделью и протестировать ответы модели на различные вопросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1932af5-a1c8-4434-a155-62832ce5dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f0aa6-483f-4809-944b-b5aa7a62c823",
   "metadata": {},
   "source": [
    "# 1. Введение и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44491ea1-15e9-4e58-b64f-e1f91eb8ee1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## уже не надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6f421b3-95b9-417c-b9e6-b4bda163ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_path = 'data/movie_conversations.txt'\n",
    "lines_path = 'data/movie_lines.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f3f4e36-5bc0-41f7-9324-a291a842bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lines_list = [] \n",
    "with open(lines_path, 'r', encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(' +++$+++ ')\n",
    "        if len(parts) == 5:\n",
    "            movie_lines_list.append(parts)\n",
    "\n",
    "movie_lines_df = pd.DataFrame(movie_lines_list, columns=['line_id', 'user_id', 'movie_id', 'character_name', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bcb8251-4987-4587-b5d4-22e30a6abe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_ids(line_ids_str):\n",
    "    return line_ids_str.strip('[]').replace(\"'\", \"\").split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cfefe0c-e250-4d9a-a210-7a84481ae21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_conversations_list = []\n",
    "with open(conversations_path, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(' +++$+++ ')\n",
    "        if len(parts) == 4:\n",
    "            movie_conversations_list.append(parts)\n",
    "\n",
    "movie_conversations_df = pd.DataFrame(movie_conversations_list, columns=['user1_id', 'user2_id', 'movie_id', 'line_ids'])\n",
    "movie_conversations_df['line_ids_list'] = movie_conversations_df['line_ids'].apply(get_line_ids)\n",
    "movie_conversations_df = movie_conversations_df.drop('line_ids', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5161a4ab-4925-4585-acbc-70dccae41782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для диалога с line_ids: ['L128378', 'L128379', 'L128380'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L128719', 'L128720'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L129148', 'L129149'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L129381', 'L129382'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L128978', 'L128979'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L129518', 'L129519'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L128708', 'L128709'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L128721', 'L128722', 'L128723'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L129276', 'L129277'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L128991', 'L128992', 'L128993', 'L128994'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L128999', 'L129000'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L129485', 'L129486', 'L129487', 'L129488', 'L129489', 'L129490', 'L129491'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L624042', 'L624043', 'L624044', 'L624045'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L624048', 'L624049'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L624050', 'L624051', 'L624052', 'L624053'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L624108', 'L624109', 'L624110'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L624260', 'L624261'] не найдено соответствующих реплик в movie_lines_df.\n",
      "Для диалога с line_ids: ['L624386', 'L624387'] не найдено соответствующих реплик в movie_lines_df.\n"
     ]
    }
   ],
   "source": [
    "dialogs = []\n",
    "for index, row in movie_conversations_df.iterrows():\n",
    "    line_ids = row['line_ids_list']\n",
    "    dialog = movie_lines_df[movie_lines_df['line_id'].isin(line_ids)]\n",
    "    if not dialog.empty:\n",
    "        dialog = dialog.set_index('line_id')\n",
    "\n",
    "        valid_line_ids = [lid for lid in line_ids if lid in dialog.index]\n",
    "        if valid_line_ids:\n",
    "            dialog = dialog.loc[valid_line_ids].reset_index()\n",
    "            dialogs.append(dialog['text'].tolist())\n",
    "        else:\n",
    "            print(f\"В диалоге с исходными line_ids: {line_ids} не найдено ни одной валидной реплики в movie_lines_df.\")\n",
    "    else:\n",
    "        print(f\"Для диалога с line_ids: {line_ids} не найдено соответствующих реплик в movie_lines_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c198a066-bd55-4c17-9b9e-762f7f494124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dialogs(dialogs, sep_token=\"[SEP]\"):\n",
    "  combined_dialogs = []\n",
    "  for dialog in dialogs:\n",
    "      if len(dialog) < 2:\n",
    "          continue  # Диалоги должны содержать как минимум две реплики\n",
    "      combined_dialog = sep_token.join(dialog)\n",
    "      combined_dialogs.append(combined_dialog.strip())  # .strip() убирает лишние пробелы\n",
    "  return combined_dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "256ea90a-a2ce-4c49-9a55-d443cb404d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_response_data = create_dialogs(dialogs, sep_token=\"[SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3f936e2-6647-4c75-8c04-ebd50d4c7208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ontext_response_data = create_context_response_pairs(dialogs, sep_token=\"[SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cbf16009-a840-43d4-ab50-e8603e53b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(context_response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e7d86408-9771-4b3a-a696-296f86b87d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_csv('DataFrame.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95360113-3de1-4807-8116-dda1e43374e8",
   "metadata": {},
   "source": [
    "## Из csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bed016-93db-4959-ac41-5daa25d9790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_csv = pd.read_csv('DataFrame.csv')\n",
    "train_df_csv.drop('Unnamed: 0', axis=1, inplace = True)\n",
    "train_df_csv.rename(columns={'0':'context'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ec6c8-1724-44b6-bcad-b4144b902648",
   "metadata": {},
   "source": [
    "# 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3a9e0-ff82-4df4-b75c-07a68d4cefb8",
   "metadata": {},
   "source": [
    "## 2.1 Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577dfed4-6092-48e4-b946-3e083f1e9682",
   "metadata": {},
   "source": [
    "1. Преобразование текста в нижний регистр\n",
    "2. Удаление HTML-тегов и спецсимволов\n",
    "3. Удаление ссылок и упоминаний\n",
    "4. Удаление знаков препинания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cffc9a-29f5-41ba-9ed3-de1e24de00aa",
   "metadata": {},
   "source": [
    "Решил не удалять стоп-слова, а также не делать лемматизацию и стемминг, чтобы GPT обучилась более точно и качественно. Надеюсь, это не сильно увеличит время обучения.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58c1166-1d88-4efb-8ed2-1b1d4c4dcf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # 1. Приведение к нижнему регистру\n",
    "        text = text.lower()\n",
    "        # 2. Удаление HTML-тегов\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        # 3. Удаление ссылок (URL)\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "        # 3. Удаление упоминаний (@user)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        # 4. Удаление знаков пунктуации (кроме апострофа)\n",
    "        text = re.sub(r'^\\w\\s\\'', '', text)\n",
    "        # Удаление лишних пробелов\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c2c2f8-049a-4971-ae0e-3773883a5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['context'] = train_df['context'].apply(preprocess_text)\n",
    "#train_df['response'] = train_df['response'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edd991ea-d13b-4493-ae21-ad3fa01c9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_csv['context'] = train_df_csv['context'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0559f1-1f77-4113-933d-97a84291610d",
   "metadata": {},
   "source": [
    "## 2.2 Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7fa3914a-f184-4b48-9cf9-150147383011",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "special_tokens_dict = {'sep_token': '[sep]'}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "config = GPT2Config.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "if num_added_toks > 0:\n",
    " model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d3fe0bd2-2f88-40b0-bfa1-ddfc223f9f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50258"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7fab896f-d980-41f3-9bdf-20dca3ec3d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50258"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d0a1238f-8db1-4e98-9997-bc1365183341",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256  # Выберите подходящую длину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b72e10f7-9004-40bb-9e5f-2acbbf231457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_prepare(example, tokenizer, max_length):\n",
    "    context = example['context']\n",
    "    tokenized = tokenizer(context, truncation=True, padding='max_length', max_length=max_length)\n",
    "    return {\n",
    "        'input_ids': tokenized['input_ids'],\n",
    "        'attention_mask': tokenized['attention_mask']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "182b08db-acb7-4f94-a906-18d146e510b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data_list = train_df_csv.apply(lambda x: tokenize_and_prepare(x, tokenizer, MAX_LENGTH), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97f239b7-af60-4095-8038-d3faa89b2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_data_csv = train_df_csv.apply(tokenize_and_prepare, axis=1).tolist()\n",
    "#tokenized_df_csv = pd.DataFrame(tokenized_data_csv)\n",
    "#tokenized_df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1b9da5ad-d11e-4fd9-83f5-fdd33a368aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря токенизатора: 50258\n",
      "Размер эмбеддингов модели: 50258\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер словаря токенизатора:\", len(tokenizer))\n",
    "print(\"Размер эмбеддингов модели:\", model.transformer.wte.num_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ee0e1-4715-488c-9574-2b43c41caa8c",
   "metadata": {},
   "source": [
    "## 2.3 Разбиение на обучающую, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0d81466d-1eca-4eed-9efa-5ae97ef13f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_list(data, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    train_data, temp_data = train_test_split(data, test_size=(1 - train_ratio), random_state=42)\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=test_ratio / (test_ratio + val_ratio), random_state=42)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_list, val_list, test_list = split_data_list(tokenized_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890cd2f-8804-45c1-ba72-5b2ad1184cc5",
   "metadata": {},
   "source": [
    "# 3. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "81d5fb44-e608-4e04-86c7-7accd8b91fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, data_list, tokenizer):\n",
    "        self.data = data_list\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        input_ids = torch.tensor(item['input_ids'], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(item['attention_mask'], dtype=torch.long)\n",
    "\n",
    "        sep_token_id = self.tokenizer.convert_tokens_to_ids('[sep]')\n",
    "        sep_index = (input_ids == sep_token_id).nonzero(as_tuple=True)[0]\n",
    "        if len(sep_index) > 0:\n",
    "            split_index = sep_index[0] + 1\n",
    "            labels = input_ids.clone()\n",
    "            labels[:split_index] = -100  # Маскируем контекст и [sep]\n",
    "        else:\n",
    "            labels = torch.full_like(input_ids, -100) # Если нет [sep], маскируем все\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ade9742e-70ff-4141-9b5d-9dfa884e3324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется GPU: NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Используется GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU не обнаружен, используется CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "1fc749b9-0c3c-491d-af7a-9a0e066d5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_pt = ConversationDataset(train_list, tokenizer)\n",
    "val_dataset_pt = ConversationDataset(val_list, tokenizer)\n",
    "test_dataset_pt = ConversationDataset(test_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "786e75a0-22be-4abc-870e-7c0c13c86253",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    gradient_accumulation_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "62998ca3-a2ce-481f-a31d-72e1b0a07915",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "8fa10918-e49c-4fb6-9528-c63e8fa53dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, tokenizer, eval_dataset, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(eval_dataset, batch_size=4)  # Adjust batch size as needed\n",
    "    total_loss = []\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Calculating Perplexity\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "    perplexity = np.exp(np.mean(total_loss))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e311a7c-991b-488b-8373-8112c63c6b59",
   "metadata": {},
   "source": [
    "## AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "9aaf5139-95fe-443c-9588-9c34cd787f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_pt,\n",
    "    eval_dataset=val_dataset_pt,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "f10cbd18-b06d-40cd-8cb3-967896af2748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43593' max='43593' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43593/43593 7:34:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.301000</td>\n",
       "      <td>3.319864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.170500</td>\n",
       "      <td>3.283113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.027200</td>\n",
       "      <td>3.278370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"./new_trained_gpt2\")\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4a84d730-506f-4ff4-8b69-1f4987f26e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_gpt2\\\\tokenizer_config.json',\n",
       " './trained_gpt2\\\\special_tokens_map.json',\n",
       " './trained_gpt2\\\\vocab.json',\n",
       " './trained_gpt2\\\\merges.txt',\n",
       " './trained_gpt2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./new_trained_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b1d64ccc-2571-4ca4-9183-87b4dad954fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./new_trained_gpt2\"\n",
    "tokenizer_1 = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer_1.pad_token = tokenizer_1.eos_token\n",
    "model_1 = GPT2LMHeadModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b37e7719-24e8-4ed0-8444-b83cb4daa9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████████████████████████████████████████████████| 3114/3114 [28:41<00:00,  1.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3445086683.9986815"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_adamW = calculate_perplexity(model_1, tokenizer_1, val_dataset_pt, device=\"cuda\")\n",
    "perplexity_adamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "4a01f9b1-03a4-4931-9c97-bce35bcc8f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель загружена на: cuda\n",
      "Промпт: how do you feel?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"how do you feel?i feel great. i'm...i'm just...it's your...your heart... the...the heart. it's like...it\"]"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_1.to(device)\n",
    "print(f\"Модель загружена на: {device}\")\n",
    "prompt_text = \"how do you feel?\"\n",
    "input_ids = tokenizer_1.encode(prompt_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "output_length = 30\n",
    "temperature = 0.8\n",
    "top_k = 50\n",
    "top_p = 0.95\n",
    "no_repeat_ngram_size = 2\n",
    "do_sample = True  # Добавьте эту строку\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_1.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=output_length + len(input_ids[0]),\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        pad_token_id=tokenizer_1.eos_token_id,\n",
    "        do_sample=do_sample,  # Включите do_sample=True здесь\n",
    "    )\n",
    "\n",
    "generated_texts = tokenizer_1.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Промпт: {prompt_text}\")\n",
    "generated_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddc11c-926e-4d80-a0e2-26ffe50cb41f",
   "metadata": {},
   "source": [
    "## Adam with scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9ceb9ed0-ffd6-4f20-8123-9fbc477e7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "36a191bb-07b5-4f69-8b46-b0448c1012f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate, weight_decay=training_args.weight_decay)\n",
    "\n",
    "warmup_steps = int(0.1 * len(train_dataset_pt)) # Например, 10% шагов для warmup\n",
    "total_steps = len(train_dataset_pt) * training_args.num_train_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Инициализация Trainer с оптимизатором и scheduler-ом\n",
    "trainer_sch = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_pt,\n",
    "    eval_dataset=val_dataset_pt,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, scheduler) # Передаем кортеж из оптимизатора и scheduler-а\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "92f47468-b65e-4fd2-8c04-3858b3ad5892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43593' max='43593' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43593/43593 5:45:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.975000</td>\n",
       "      <td>3.355036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.991100</td>\n",
       "      <td>3.355534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.927300</td>\n",
       "      <td>3.358753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43593, training_loss=2.8820528949176367, metrics={'train_runtime': 20714.9024, 'train_samples_per_second': 8.418, 'train_steps_per_second': 2.104, 'total_flos': 2.2780615163904e+16, 'train_loss': 2.8820528949176367, 'epoch': 3.0})"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sch.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "76777289-9798-440d-95f9-60e9e0ab5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "trainer_sch.save_model(\"./scheduled_AdamW_trained_gpt2\")\n",
    "tokenizer.save_pretrained(\"./scheduled_AdamW_trained_gpt2\")\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "54f377c3-3b0a-4ad1-be5f-2c6026c511b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./scheduled_AdamW_trained_gpt2\"\n",
    "tokenizer_2 = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer_2.pad_token = tokenizer_2.eos_token\n",
    "model_2 = GPT2LMHeadModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "bb0152b7-1f5a-4983-9a09-22aea7671553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель загружена на: cuda\n",
      "Промпт: how do you feel now?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"how do you feel now?oh, nothing. i'm fine.is that all you've got? you're a bad liar. what's this? is this a\"]"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_2.to(device)\n",
    "print(f\"Модель загружена на: {device}\")\n",
    "prompt_text = \"how do you feel now?\"\n",
    "input_ids = tokenizer_2.encode(prompt_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "output_length = 30\n",
    "temperature = 0.8\n",
    "top_k = 50\n",
    "top_p = 0.95\n",
    "no_repeat_ngram_size = 2\n",
    "do_sample = True  # Добавьте эту строку\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_2.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=output_length + len(input_ids[0]),\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        pad_token_id=tokenizer_2.eos_token_id,\n",
    "        do_sample=do_sample,\n",
    "    )\n",
    "\n",
    "generated_texts = tokenizer_2.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Промпт: {prompt_text}\")\n",
    "generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "4e314344-ea36-4d0c-8b0e-73e09848df90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████████████████████████████████████████████████| 3114/3114 [28:47<00:00,  1.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81552387.70238216"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_scheduled_AdamW = calculate_perplexity(model_2, tokenizer_2, val_dataset_pt, device=\"cuda\")\n",
    "perplexity_scheduled_AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44642e15-ade7-4613-8ae4-46b7152be5a6",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d2a439dd-8ced-4d4a-b154-a5d28603a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=training_args.learning_rate, weight_decay=training_args.weight_decay)\n",
    "\n",
    "# Инициализация Trainer с оптимизатором (без scheduler-а)\n",
    "trainer_sgd = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_pt,\n",
    "    eval_dataset=val_dataset_pt,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, None) # Передаем кортеж: оптимизатор и None для scheduler-а\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d994265f-d08c-4203-80db-4ac6733564cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43593' max='43593' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43593/43593 5:25:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.364800</td>\n",
       "      <td>3.387300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.923600</td>\n",
       "      <td>3.374639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.980300</td>\n",
       "      <td>3.370776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43593, training_loss=2.809060628412021, metrics={'train_runtime': 19504.818, 'train_samples_per_second': 8.94, 'train_steps_per_second': 2.235, 'total_flos': 2.2780615163904e+16, 'train_loss': 2.809060628412021, 'epoch': 3.0})"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sgd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e19b2d29-9161-4b4d-983b-691322c7c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "trainer_sgd.save_model(\"./sgd_trained_gpt2\")\n",
    "tokenizer.save_pretrained(\"./sgd_trained_gpt2\")\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "c952d1b3-acd0-46e7-ac9c-f4bf4b01b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./sgd_trained_gpt2\"\n",
    "tokenizer_3 = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer_3.pad_token = tokenizer_3.eos_token\n",
    "model_3 = GPT2LMHeadModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "24f58c4f-581a-463d-8c6a-f3c38ab358de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████████████████████████████████████████████████| 3114/3114 [33:50<00:00,  1.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269724329.7913781"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_sgd = calculate_perplexity(model_3, tokenizer_3, val_dataset_pt, device=\"cuda\")\n",
    "perplexity_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef30aea-f673-4d94-9b9b-77b7d2ce3a9e",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "34d334d9-78e7-4b33-b08f-09ae5b6e858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(model.parameters(), lr=training_args.learning_rate, weight_decay=training_args.weight_decay)\n",
    "\n",
    "# Инициализация Trainer с оптимизатором (без scheduler-а)\n",
    "trainer_rms = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_pt,\n",
    "    eval_dataset=val_dataset_pt,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, None) # Передаем кортеж: оптимизатор и None для scheduler-а\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "d3a48f37-81b7-4a8a-b647-b3af67625401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43593' max='43593' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43593/43593 6:34:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.514700</td>\n",
       "      <td>6.236183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.203000</td>\n",
       "      <td>6.130835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.939400</td>\n",
       "      <td>5.806921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43593, training_loss=5.93833638871744, metrics={'train_runtime': 23670.6, 'train_samples_per_second': 7.366, 'train_steps_per_second': 1.842, 'total_flos': 2.2780615163904e+16, 'train_loss': 5.93833638871744, 'epoch': 3.0})"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_rms.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "8393f6c0-9f68-4e13-a071-662e542dfa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "trainer_sgd.save_model(\"./rms_trained_gpt2\")\n",
    "tokenizer.save_pretrained(\"./rms_trained_gpt2\")\n",
    "print(\"Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "bae575cc-9a18-4300-bd58-196b1761d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./rms_trained_gpt2\"\n",
    "tokenizer_4 = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer_4.pad_token = tokenizer_4.eos_token\n",
    "model_4 = GPT2LMHeadModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "bfc5ebdc-d6fa-41e0-8560-f444b8e8d931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████████████████████████████████████████████████| 3114/3114 [28:48<00:00,  1.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156302.10956592893"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_rms = calculate_perplexity(model_4, tokenizer_4, val_dataset_pt, device=\"cuda\")\n",
    "perplexity_rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df162c-144a-4755-84e1-5308f7410c03",
   "metadata": {},
   "source": [
    "BLEU и ROUGE рассчитать не получилось корректно, т.к. я использовал в качестве labels замаскированный input_ids. Из-за этого по сути на вход отдельно не поступало эталонных ответов (переучивать модель сейчас уже, к сожалению, нет времени)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b902f-c7e8-4c65-8015-dbe798a52551",
   "metadata": {},
   "source": [
    "По perplexity лучшие результаты были получены с использованием оптимизатора RMSprop, но в целом, при диалоге с нейронкой видно, что она дообучена на киношных диалогах. Модель отвечает классическими клише из кино, ведет себя как Джеймс Бонд или Джесси из Breaking Bad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
